version: "3.9"

services:
  nginx:
    image: nginx:1.25-alpine
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    ports: 
      - "80:80"
      - "443:443"
    depends_on: 
      - api
      - web
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
      POSTGRES_HOST_AUTH_METHOD: "scram-sha-256"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  valkey:
    image: valkey/valkey:7-alpine
    command: 
      - valkey-server
      - --appendonly yes
      - --maxmemory 512mb
      - --maxmemory-policy allkeys-lru
      - --tcp-backlog 511
      - --tcp-keepalive 60
      - --timeout 300
    volumes:
      - valkeydata:/data
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY}
      MINIO_BROWSER: "off"  # Disable console in production
    command: server /data
    volumes:
      - miniodata:/data
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  api:
    build: 
      context: ../apps/api
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
    env_file: ${ENV_FILE:-.env.production}
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?schema=public&sslmode=require
      REDIS_URL: ${REDIS_URL}
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 512M
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  web:
    build:
      context: ../apps/web
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
        NEXT_PUBLIC_API_URL: https://${DOMAIN_API}
    env_file: ${ENV_FILE:-.env.production}
    environment:
      NODE_ENV: production
    depends_on:
      - api
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s

  worker:
    build:
      context: ..
      dockerfile: apps/worker/Dockerfile
    env_file: ${ENV_FILE:-.env.production}
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?schema=public&sslmode=require
      REDIS_URL: ${REDIS_URL}
      WORKER_CONCURRENCY: ${WORKER_CONCURRENCY:-5}
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring services with resource limits
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheusdata:/prometheus
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafanadata:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,redis-datasource
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN_APP}
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  loki:
    image: grafana/loki:2.9.0
    volumes:
      - ./loki/config.yml:/etc/loki/config.yml:ro
      - lokidata:/loki
    command: ["-config.file=/etc/loki/config.yml"]
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  promtail:
    image: grafana/promtail:3.0.0
    volumes:
      - ./promtail/config.yml:/etc/promtail/config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
    command: ["-config.file=/etc/promtail/config.yml"]
    depends_on:
      - loki
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M

volumes:
  pgdata:
    driver: local
  valkeydata:
    driver: local
  miniodata:
    driver: local
  prometheusdata:
    driver: local
  grafanadata:
    driver: local
  lokidata:
    driver: local

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16